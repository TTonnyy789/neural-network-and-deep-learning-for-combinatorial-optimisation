#%%#
### Step 1 ######################################################################
### Import the required libraries

import pandas as pd
import numpy as np
import json
import networkx as nx
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch_geometric.data import Data
from torch_geometric.nn import GCNConv


## 


#%%#
### Encoder and Decoder ######################################################################


## Each node in the graph is represented by a feature vector, and positional encodings are added to these features to provide positional information
class PositionalEncoding(nn.Module):
    def __init__(self, d_model, max_len=5000):  ## The PositionalEncoding class defines the positional encoding layer, which adds positional information to the input features
        super(PositionalEncoding, self).__init__()  ## For the first step, the positional encoding layer generates a matrix of zeros with the specified maximum length and dimension
        pe = torch.zeros(max_len, d_model)  ## The positional encoding is calculated using the sine and cosine functions with different frequencies
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))  
        pe[:, 0::2] = torch.sin(position * div_term)  
        pe[:, 1::2] = torch.cos(position * div_term)
        pe = pe.unsqueeze(0).transpose(0, 1)
        self.register_buffer('pe', pe)

    def forward(self, x):
        return x + self.pe[:x.size(0), :]


## The encoder consists of multiple layers of self-attention and feed-forward neural networks
## The dimension of the input is first projected to the hidden dimension using a linear layer, and then positional encodings are added to the input, which is then passed through the transformer encoder
class TransformerEncoder(nn.Module):
    def __init__(self, input_dim, hidden_dim, num_heads, num_layers):
        super(TransformerEncoder, self).__init__()
        self.embedding = nn.Linear(input_dim, hidden_dim)
        self.positional_encoding = PositionalEncoding(hidden_dim)
        encoder_layers = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=num_heads)
        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)

    def forward(self, src):
        src = self.embedding(src)
        src = self.positional_encoding(src)
        output = self.transformer_encoder(src)
        return output


## The decoder is similar to the encoder, but it also includes a linear layer to output the predicted sequence
## The dimension of the output sequence is the same as the input dimension, and the output sequence is generated by sampling from the output distribution
class TransformerDecoder(nn.Module):
    def __init__(self, hidden_dim, output_dim, num_heads, num_layers):
        super(TransformerDecoder, self).__init__()
        self.embedding = nn.Linear(output_dim, hidden_dim)
        decoder_layers = nn.TransformerDecoderLayer(d_model=hidden_dim, nhead=num_heads)
        self.transformer_decoder = nn.TransformerDecoder(decoder_layers, num_layers=num_layers)
        self.fc_out = nn.Linear(hidden_dim, output_dim)

    def forward(self, tgt, memory):
        tgt = self.embedding(tgt)
        output = self.transformer_decoder(tgt, memory)
        output = self.fc_out(output)
        return output


## Integrates the encoder and decoder into a complete model
class PointerNetwork(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim, num_heads, num_layers):
        super(PointerNetwork, self).__init__()
        self.encoder = TransformerEncoder(input_dim, hidden_dim, num_heads, num_layers)
        self.decoder = TransformerDecoder(hidden_dim, output_dim, num_heads, num_layers)

    def forward(self, src, tgt):
        memory = self.encoder(src)
        output = self.decoder(tgt, memory)
        return output



#%%#
### Example 1 ######################################################################


class GCNEncoder(nn.Module):
    def __init__(self, input_dim, hidden_dim):  ## this is mainly responsible for the graph convolution operation, and  The GCNConv layer takes the input features and the edge index as input and applies the graph convolution operation
        super(GCNEncoder, self).__init__()  ## For the first GCNConv layer, the input dimension is the node feature dimension and the hidden dimension is the output dimension
        self.conv1 = GCNConv(input_dim, hidden_dim)  ## The output of the first GCNConv layer is passed through a ReLU activation function and then through another GCNConv layer
        self.conv2 = GCNConv(hidden_dim, hidden_dim)  ## The output of the second GCNConv layer is the final output of the encoder

    def forward(self, x, edge_index):  ## The forward method takes the node features x and the edge index as input and applies the graph convolution operation
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = self.conv2(x, edge_index)
        return x
## After executing the forward method, the output of the encoder is the node embeddings, which are used as input to the decoder, and the output is consists of the information of the graph


class PointerDecoder(nn.Module):
    def __init__(self, hidden_dim, output_dim):
        ## The PointerDecoder class defines the decoder part of the pointer network
        ## The decoder consists of an LSTM layer followed by a linear layer
        super(PointerDecoder, self).__init__()
        self.lstm = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)
        self.pointer = nn.Linear(hidden_dim, output_dim)

    def forward(self, h, seq_len):
        batch_size = h.size(0)
        dec_input = torch.zeros(batch_size, 1, h.size(2)).to(h.device)
        dec_hidden = (torch.zeros(1, batch_size, h.size(2)).to(h.device),
                      torch.zeros(1, batch_size, h.size(2)).to(h.device))
        outputs = []
        for _ in range(seq_len):
            dec_output, dec_hidden = self.lstm(dec_input, dec_hidden)
            pointer_logits = self.pointer(dec_output)
            outputs.append(pointer_logits)
            dec_input = dec_output
        return torch.cat(outputs, dim=1)


class PointerNetwork(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(PointerNetwork, self).__init__()
        self.encoder = GCNEncoder(input_dim, hidden_dim)
        self.decoder = PointerDecoder(hidden_dim, output_dim)

    def forward(self, x, edge_index, seq_len):
        h = self.encoder(x, edge_index)
        output = self.decoder(h.unsqueeze(0), seq_len)
        return output



# Example TSP graph data
nodes = torch.tensor([[0, 0], [1, 0], [1, 1], [0, 1]], dtype=torch.float)
edge_index = torch.tensor([[0, 0, 0, 1, 1, 2, 2, 3], [1, 2, 3, 0, 2, 0, 3, 0]], dtype=torch.long)
edge_attr = torch.tensor([1.0, 1.414, 1.0, 1.0, 1.0, 1.414, 1.0, 1.0], dtype=torch.float)
data = Data(x=nodes, edge_index=edge_index, edge_attr=edge_attr)

# Initialize model and optimizer
input_dim = 2  # Node feature dimension
hidden_dim = 4  # Hidden dimension
output_dim = 4  # Number of nodes to visit

model = PointerNetwork(input_dim, hidden_dim, output_dim)
optimizer = optim.Adam(model.parameters(), lr=0.01)

# Example training function
def train_model(model, data, optimizer, num_epochs=1000):
    for epoch in range(num_epochs):
        optimizer.zero_grad()
        output = model(data.x, data.edge_index, seq_len=4)
        loss = F.cross_entropy(output.view(-1, output_dim), torch.tensor([0, 1, 2, 3]))
        loss.backward()
        optimizer.step()
        print(f"Epoch {epoch}, Loss: {loss.item()}")

# Train the model
train_model(model, data, optimizer)

# Apply the trained model to generate a solution
def generate_solution(model, data):
    model.eval()
    with torch.no_grad():
        output = model(data.x, data.edge_index, seq_len=4)
        solution = torch.argmax(output, dim=2)
        return solution

solution = generate_solution(model, data)
print("Generated solution:", solution)




# %%
